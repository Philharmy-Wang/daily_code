import os
import json
import cv2

def convert_yolo_to_coco(yolo_label_dir, img_dir, output_json_path):
    coco_output = {
        "info": {
            "description": "Converted YOLO dataset",
            "url": "",
            "version": "1.0",
            "year": 2023,
            "contributor": "",
            "date_created": "2023/10/23"
        },
        "licenses": [],
        "images": [],
        "annotations": [],
        "categories": [
            {"id": 1, "name": "fire", "supercategory": "object"},
            {"id": 2, "name": "smoke", "supercategory": "object"}
        ]
    }

    annotation_id = 1
    image_id = 1

    for filename in os.listdir(yolo_label_dir):
        if filename.endswith(".txt"):
            image_filename = filename.replace(".txt", ".jpg")
            image_path = os.path.join(img_dir, image_filename)
            img = cv2.imread(image_path)
            height, width = img.shape[:2]

            image_info = {
                "file_name": image_filename,
                "height": height,
                "width": width,
                "id": image_id
            }
            coco_output["images"].append(image_info)

            yolo_label_path = os.path.join(yolo_label_dir, filename)
            with open(yolo_label_path, "r") as file:
                for line in file:
                    class_id, x_center, y_center, width, height = map(float, line.strip().split())
                    class_id = int(class_id) + 1  # class ids start at 1
                    x_min = (x_center - width / 2) * width
                    y_min = (y_center - height / 2) * height
                    bbox_width = width * width
                    bbox_height = height * height

                    annotation_info = {
                        "id": annotation_id,
                        "image_id": image_id,
                        "category_id": class_id,
                        "iscrowd": 0,
                        "area": bbox_width * bbox_height,
                        "bbox": [x_min, y_min, bbox_width, bbox_height],
                        "segmentation": [],  # segmentation is not available in YOLO format
                        "width": width,
                        "height": height
                    }
                    coco_output["annotations"].append(annotation_info)
                    annotation_id += 1

            image_id += 1

    with open(output_json_path, "w") as output_file:
        json.dump(coco_output, output_file)

# Set your paths
yolo_label_dir_train = 'C:/Users/12715/Documents/GitHub/mmdetection/dataset/VOCdevkit-rs/labels/train'
img_dir_train = 'C:/Users/12715/Documents/GitHub/mmdetection/dataset/VOCdevkit-rs/images/train'
output_json_path_train = 'C:/Users/12715/Documents/GitHub/mmdetection/dataset/VOCdevkit-rs/train.json'

yolo_label_dir_val = 'C:/Users/12715/Documents/GitHub/mmdetection/dataset/VOCdevkit-rs/labels/val'
img_dir_val = 'C:/Users/12715/Documents/GitHub/mmdetection/dataset/VOCdevkit-rs/images/val'
output_json_path_val = 'C:/Users/12715/Documents/GitHub/mmdetection/dataset/VOCdevkit-rs/val.json'

# Convert train and val datasets
convert_yolo_to_coco(yolo_label_dir_train, img_dir_train, output_json_path_train)
convert_yolo_to_coco(yolo_label_dir_val, img_dir_val, output_json_path_val)
